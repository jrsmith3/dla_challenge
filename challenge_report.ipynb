{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning Analytics challenge report\n",
    "\n",
    "In this report I discuss how I addressed the DLA challenge. The report starts with the my configuration/devops of the TK1. Next is a section on a simple problem of categorizing handwritten digits based on code and an example from Nielsen's [\"Neural Networks and Deep Learning\"](http://neuralnetworksanddeeplearning.com/). Finally I report on a partial solution to a more difficult problem of applying a neural network to a physical simulation. Specifically, approximating the value of the so-called maximum motive of a thermoelectron engine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TK1 configuraiton and devops\n",
    "============================\n",
    "The TK1 ships with an installation of ubuntu; there's a user named ubuntu with password ubuntu.\n",
    "I plugged the TK1 into the power supply and connected it via an ethernet cable to the network; all communication with the TK1 was performed via SSH.\n",
    "According to the setup instructions, I must [execute a command so that `apt` doesn't clobber `libglx.so`](http://elinux.org/Jetson_TK1#An_important_step_before_connecting_the_Jetson_to_Internet) **before** connecting the board to the internet. Therefore, I unplugged my router from my cable modem.\n",
    "\n",
    "For the sake of convenience and good systems administration, I wanted to configure the TK1 so that I could log in without a password using an SSH key.\n",
    "I also wanted a user named \"jrsmith3\" to match the username on my notebook in which I will install all of the code and administer the machine.\n",
    "Finally, I wanted to change the default password for the \"ubuntu\" user for the sake of security.\n",
    "\n",
    "Change `ubuntu` user password\n",
    "-----------------------------\n",
    "First, I logged into the TK1 via the user \"ubuntu.\"\n",
    "I used the [passwordstore utility](http://www.passwordstore.org/) on my notebook to generate a difficult-to-guess password for this machine.\n",
    "\n",
    "password: U33HzPE-(.vIQJ\\:3kj_\n",
    "\n",
    "\n",
    "Prevent `apt` from clobbering `libglx.so`\n",
    "-----------------------------------------\n",
    "I just [followed the instructions](http://elinux.org/Jetson_TK1#An_important_step_before_connecting_the_Jetson_to_Internet). I also plugged the router back into the cable modem and I'm back on the internet.\n",
    "\n",
    "\n",
    "Create a user `jrsmith3`\n",
    "------------------------\n",
    "Pretty simple.\n",
    "\n",
    "```\n",
    "$ sudo adduser jrsmith3\n",
    "Adding user `jrsmith3' ...\n",
    "Adding new group `jrsmith3' (1001) ...\n",
    "Adding new user `jrsmith3' (1001) with group `jrsmith3' ...\n",
    "Creating home directory `/home/jrsmith3' ...\n",
    "Copying files from `/etc/skel' ...\n",
    "Enter new UNIX password: \n",
    "Retype new UNIX password: \n",
    "passwd: password updated successfully\n",
    "Changing the user information for jrsmith3\n",
    "Enter the new value, or press ENTER for the default\n",
    "    Full Name []: Joshua Ryan Smith\n",
    "    Room Number []: \n",
    "    Work Phone []: \n",
    "    Home Phone []: \n",
    "    Other []: joshua.r.smith@gmail.com\n",
    "Is the information correct? [Y/n] y\n",
    "Adding new user `jrsmith3' to extra groups ...\n",
    "Adding user `jrsmith3' to group `video' ...\n",
    "```\n",
    "\n",
    "\n",
    "Give user `jrsmith3` sudo access\n",
    "--------------------------------\n",
    "For sysadmin purposes.\n",
    "\n",
    "```\n",
    "ubuntu@tegra-ubuntu:~$ sudo usermod -a -G sudo jrsmith3\n",
    "```\n",
    "\n",
    "\n",
    "Allow ssh logins via ssh keys\n",
    "-----------------------------\n",
    "Maybe this feature is already set up. I will try to copy my public ssh key from gamma over to the TX1. First, I had to create an `.ssh` directory on the TX1.\n",
    "\n",
    "```\n",
    "jrsmith3@tegra-ubuntu:~$ mkdir .ssh\n",
    "```\n",
    "\n",
    "Then I use scp to copy my ssh key to the TX1.\n",
    "\n",
    "```\n",
    "gamma:$ scp -rCp ~/.ssh/id_rsa.pub jrsmith3@tegra-ubuntu:.ssh\n",
    "jrsmith3@tegra-ubuntu's password: \n",
    "id_rsa.pub                                    100%  396     0.4KB/s   00:00\n",
    "```\n",
    "\n",
    "After copying the public key, I added it to the `~/.ssh/authorized_keys` file.\n",
    "\n",
    "\n",
    "Update apt and packages\n",
    "-----------------------\n",
    "Simple.\n",
    "\n",
    "```\n",
    "sudo apt-add-repository universe\n",
    "sudo apt-get update\n",
    "```\n",
    "\n",
    "I will also install `bash-completion` and `command-not-found` as suggested in the instructions.\n",
    "\n",
    "At this point I'm going to have to modify files in `/etc` and so I should probably set up `etckeeper`. To do that, I should also probably update the packages.\n",
    "\n",
    "\n",
    "Install `etckeeper`, `git`, and other utils\n",
    "-------------------------------------------\n",
    "I need to modify some things in `~etc`, so out of an abundance of caution I will [install `etckeeper`](https://help.ubuntu.com/lts/serverguide/etckeeper.html) as well.\n",
    "\n",
    "```\n",
    "sudo apt-get install etckeeper\n",
    "```\n",
    "\n",
    "I'm pretty sure the above pulled in `bzr` and set up `/etc` as a `bzr` repo. [I want git instead](http://evilrouters.net/2011/02/18/using-etckeeper-with-git-on-ubuntu/).\n",
    "\n",
    "```\n",
    "sudo apt-get install -y git-core\n",
    "```\n",
    "\n",
    "Configure git\n",
    "\n",
    "```\n",
    "$ git config --global user.name \"Joshua Ryan Smith\"\n",
    "$ git config --global user.email joshua.r.smith@gmail.com\n",
    "```\n",
    "\n",
    "After the above commands, I modified `/etc/etckeeper/etckeeper.conf` to use git. I had to unintialize `etckeeper` so that it would remove the bzr repo and use git instead.\n",
    "\n",
    "```\n",
    "$ sudo etckeeper uninit\n",
    "[sudo] password for jrsmith3: \n",
    "** Warning: This will DESTROY all recorded history for /etc,\n",
    "** including the bzr repository.\n",
    "\n",
    "Are you sure you want to do this? [yN] y\n",
    "Proceeding..\n",
    "```\n",
    "\n",
    "Next, I initialize `etckeeper`.\n",
    "\n",
    "```\n",
    "$ sudo etckeeper init\n",
    "Initialized empty Git repository in /etc/.git/\n",
    "$ sudo etckeeper commit \"Initial commit.\"\n",
    "```\n",
    "\n",
    "Now everything looks right.\n",
    "\n",
    "\n",
    "Upgrade packages\n",
    "----------------\n",
    "Simple.\n",
    "\n",
    "```\n",
    "sudo apt-get upgrade\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Anaconda Python distribution for development\n",
    "\n",
    "The [anaconda python distribution](https://www.continuum.io/downloads) provided by Continuum.io makes managing python packages and environments very simple -- particularly when it comes to installing the typical numerical stack such as `numpy`, `scipy`, etc.\n",
    "\n",
    "Continuum has an [anaconda for armv7l](https://www.continuum.io/content/conda-support-raspberry-pi-2-and-power8-le) which is the architecture of the TK1:\n",
    "\n",
    "```\n",
    "$ uname -m\n",
    "armv7l\n",
    "```\n",
    "\n",
    "I will need to install miniconda, but `numpy`, `scipy`, and a few other packages have been built. I'm using the [latest armv7l](http://repo.continuum.io/miniconda/Miniconda-latest-Linux-armv7l.sh). \n",
    "\n",
    "The md5sum matches, next to install:\n",
    "\n",
    "```\n",
    "$ bash Miniconda-latest-Linux-armv7l.sh\n",
    "\n",
    "# ...\n",
    "# Superfluous output\n",
    "# ...\n",
    "\n",
    "installation finished.\n",
    "Do you wish the installer to prepend the Miniconda install location\n",
    "to PATH in your /home/jrsmith3/.bashrc ? [yes|no]\n",
    "[no] >>> yes\n",
    "\n",
    "Prepending PATH=/home/jrsmith3/miniconda/bin to PATH in /home/jrsmith3/.bashrc\n",
    "A backup will be made to: /home/jrsmith3/.bashrc-miniconda.bak\n",
    "\n",
    "\n",
    "For this change to become active, you have to open a new terminal.\n",
    "\n",
    "Thank you for installing Miniconda!\n",
    "```\n",
    "\n",
    "The installer even backed up my old `.bashrc` file. I logged out and rebooted because ubuntu said I should."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating python environments for development\n",
    "\n",
    "Instead of installing packages system-wide, it is good development practice to create a virtual environment and install the necessary packages there. Additionally, some of my packages have been built using conda and can be installed into such an environment.\n",
    "\n",
    "Creating an environment on the TK1 with conda is straightforward. First, execute the command to create a barebones python environment in the `env` subdirectory of the current directory:\n",
    "\n",
    "```bash\n",
    "conda create -yp ./env python\n",
    "```\n",
    "\n",
    "Next, install the `ipython` shell and my `tec` package into the environment.\n",
    "\n",
    "```bash\n",
    "conda install -y -c jrsmith3 tec ipython -p ./env\n",
    "```\n",
    "\n",
    "The `-c jrsmith3` flag tells conda to search my channel on anaconda.org for the `tec` package.\n",
    "\n",
    "Finally, the environment can be activated\n",
    "\n",
    "```bash\n",
    "source activate ./env\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Easy problem: Neural Networks and Deep Learning\n",
    "\n",
    "Michael Nielsen has written a very nice [book](http://neuralnetworksanddeeplearning.com/) introducing Neural Networks and Deep Learning. This book comes with a [repository](https://github.com/mnielsen/neural-networks-and-deep-learning) which includes code implementing various neural networks as well as example data for training and validation. Specifically, the repo contains the [MNIST data set](http://yann.lecun.com/exdb/mnist/) which features more than 10,000 digitized, handwritten digits and their correct classification. Implementing a neural network to classify these digits is as simple as following the code on the book's website.\n",
    "\n",
    "First, clone the repo and change directories into it (on the TK1):\n",
    "\n",
    "```bash\n",
    "$ pwd\n",
    "/home/jrsmith3/Documents\n",
    "\n",
    "$ git clone https://github.com/mnielsen/neural-networks-and-deep-learning.git\n",
    "$ cd neural-networks-and-deep-learning\n",
    "```\n",
    "\n",
    "Next, create a conda environment in the root directory of the repo and install numpy, scipy, and ipython.\n",
    "\n",
    "```bash\n",
    "$ conda create -yp ./env python\n",
    "$ conda install -y numpy scipy ipython -p ./env\n",
    "```\n",
    "\n",
    "The following code is located at `/home/jrsmith3/Documents/neural-networks-and-deep-learning/src/easy_problem.py` and can be run once the conda environment has been activated. Note that neither `easy_problem.py` nor the conda environment in `env` has been checked into the `neural-networks-and-deep-learning` repository on the TK1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 8979 / 10000\n",
      "Epoch 1: 9140 / 10000\n",
      "Epoch 2: 9232 / 10000\n",
      "Epoch 3: 9313 / 10000\n",
      "Epoch 4: 9313 / 10000\n",
      "Epoch 5: 9365 / 10000\n",
      "Epoch 6: 9363 / 10000\n",
      "Epoch 7: 9322 / 10000\n",
      "Epoch 8: 9388 / 10000\n",
      "Epoch 9: 9410 / 10000\n",
      "Epoch 10: 9416 / 10000\n",
      "Epoch 11: 9417 / 10000\n",
      "Epoch 12: 9402 / 10000\n",
      "Epoch 13: 9394 / 10000\n",
      "Epoch 14: 9428 / 10000\n",
      "Epoch 15: 9435 / 10000\n",
      "Epoch 16: 9446 / 10000\n",
      "Epoch 17: 9443 / 10000\n",
      "Epoch 18: 9419 / 10000\n",
      "Epoch 19: 9468 / 10000\n",
      "Epoch 20: 9443 / 10000\n",
      "Epoch 21: 9466 / 10000\n",
      "Epoch 22: 9467 / 10000\n",
      "Epoch 23: 9453 / 10000\n",
      "Epoch 24: 9467 / 10000\n",
      "Epoch 25: 9472 / 10000\n",
      "Epoch 26: 9456 / 10000\n",
      "Epoch 27: 9439 / 10000\n",
      "Epoch 28: 9439 / 10000\n",
      "Epoch 29: 9424 / 10000\n",
      "316.686872005\n"
     ]
    }
   ],
   "source": [
    "import mnist_loader\n",
    "import network\n",
    "import time\n",
    "\n",
    "training_data, validation_data, test_data = mnist_loader.load_data_wrapper()\n",
    "net = network.Network([784, 30, 10])\n",
    "\n",
    "start_time = time.time()\n",
    "net.SGD(training_data, 30, 10, 3.0, test_data=test_data)\n",
    "print time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown above, my MacBook Air required about 5 minutes for training and correctly identified 95% of the digits in the best case scenario. The TK1 obtained similar success in identifying the digits but required around 12 minutes to complete the training runs. Typical output for the training run on the TK1 is as follows:\n",
    "\n",
    "```\n",
    "In [1]: %run easy_problem.py\n",
    "Epoch 0: 9032 / 10000\n",
    "Epoch 1: 9229 / 10000\n",
    "Epoch 2: 9239 / 10000\n",
    "Epoch 3: 9377 / 10000\n",
    "Epoch 4: 9397 / 10000\n",
    "Epoch 5: 9388 / 10000\n",
    "Epoch 6: 9450 / 10000\n",
    "Epoch 7: 9449 / 10000\n",
    "Epoch 8: 9459 / 10000\n",
    "Epoch 9: 9483 / 10000\n",
    "Epoch 10: 9470 / 10000\n",
    "Epoch 11: 9508 / 10000\n",
    "Epoch 12: 9493 / 10000\n",
    "Epoch 13: 9535 / 10000\n",
    "Epoch 14: 9500 / 10000\n",
    "Epoch 15: 9504 / 10000\n",
    "Epoch 16: 9505 / 10000\n",
    "Epoch 17: 9492 / 10000\n",
    "Epoch 18: 9538 / 10000\n",
    "Epoch 19: 9519 / 10000\n",
    "Epoch 20: 9520 / 10000\n",
    "Epoch 21: 9531 / 10000\n",
    "Epoch 22: 9525 / 10000\n",
    "Epoch 23: 9514 / 10000\n",
    "Epoch 24: 9523 / 10000\n",
    "Epoch 25: 9518 / 10000\n",
    "Epoch 26: 9516 / 10000\n",
    "Epoch 27: 9543 / 10000\n",
    "Epoch 28: 9525 / 10000\n",
    "Epoch 29: 9524 / 10000\n",
    "678.137501001\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More difficult problem: Predicting behavior of a complicated physical system\n",
    "\n",
    "Neural networks are typically employed in computer vision applications such as image classification (i.e. finding pictures of dogs or cats) and handwriting recognition like the example above. \n",
    "Although NNs seem to mostly be used for image processing applications, there are some reports of applying NNs to problems in physics.\n",
    "For example, [Grzeszczuk et.al.](http://dx.doi.org/10.1145/280814.280816) used a neural network to generate physically plausible computer animations.\n",
    "After training, their network was able to produce physically realistic motion faster than the approach of solving the system's equations of motion.\n",
    "\n",
    "If a neural network can be trained to approximate solutions to problems of motion faster than a full simulation, then it stands to reason that a neural network could be trained to control a robot or autonomous vehicle (e.g. drone aircraft, driverless car, etc.).\n",
    "Consider the case where a neural network controls a driverless car; one likely task would be to design control system to avoid pedestrians.\n",
    "Building a prototype driverless car and training course would be costly in terms of money as well as time: each training run would occur in realtime.\n",
    "On the other hand, despite the computational costs, such training runs could be simulated by solving the relevant physical equations in order to avoid the costly (in terms of money) prototype buildout.\n",
    "Indeed, [Ford employs exactly this strategy for its autonomous vehicle program](http://spectrum.ieee.org/view-from-the-valley/transportation/self-driving/autonomous-vehicles-learn-by-playing-video-games).\n",
    "\n",
    "Given the limited amount of time to work on this project, I chose a much simpler problem to solve which is based on a physical simulation.\n",
    "Specifically the task is to determine the value of the maximum motive for a thermoelectron engine given the operating parameters of the device.\n",
    "This problem is good because it is not trivial but it is not as complicated as the autonomous vehicle examples described above.\n",
    "Moreover, I've written code to perform this simulation and so it is suited for the problem of generating training data for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background on thermoelectron engine\n",
    "\n",
    "A thermoelectron engine, also known as a thermoelectron energy converter or TEC, is a thermodynamic heat engine consisting of two electrodes enclosed in an evacuated container.\n",
    "The electrodes are separated by a distance named the interelectrode spacing.\n",
    "The emitter electrode is held at a higher temperature than the collector electrode, and electrons are emitted via the phenomenon of thermoelectron emission.\n",
    "These thermoelectrons travel across the interelectrode space and arrive at the collector where they are absorbed. \n",
    "The electrons then travel through a lead, through an external load where work is done, and back to the emitter to complete the circuit.\n",
    "\n",
    "![Schematic-tec](tec_schematic.png)\n",
    "\n",
    "The interesting output parameters of this device, such as the output power density and efficiency, are fully determined by the electron transport across the device.\n",
    "Specifically, the output parameters are determined by a quantity known as the maximum motive of the device.\n",
    "This quantity is essentially the highest barrier electrons encounter as they traverse the device.\n",
    "There is a difficulty in calculating the maximum motive because the electron transport cannot be expressed by a closed-form equation.\n",
    "Instead, a set of coupled differential equations must be self-consistently solved.\n",
    "\n",
    "The [`tec`](https://github.com/jrsmith3/tec) python module I wrote implements a numerical solution to the electron transport problem described above and is intended to be used as the simulator to generate the training and validation data for the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing `tec` on the TK1\n",
    "\n",
    "ADD COPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import time\n",
    "import json\n",
    "import sys\n",
    "import tec\n",
    "import numpy as np\n",
    "import network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "em_params = {\"temp\": 1000.,\n",
    "             \"barrier\": 2.,\n",
    "             \"richardson\": 10., }\n",
    "\n",
    "co_params = {\"temp\": 300.,\n",
    "             \"barrier\": 1.,\n",
    "             \"richardson\": 10.,\n",
    "             \"position\": 10., }\n",
    "\n",
    "emitter_temps = [(\"emitter\", \"temp\", val) for val in np.linspace(300, 2000, 10)]\n",
    "emitter_barriers = [(\"emitter\", \"barrier\", val) for val in np.linspace(1, 4, 10)]\n",
    "collector_barriers = [(\"collector\", \"barrier\", val) for val in np.linspace(1, 4, 10)]\n",
    "collector_voltages = [(\"collector\", \"voltage\", val) for val in np.linspace(0, 2, 20)]\n",
    "collector_positions = [(\"collector\", \"position\", val) for val in np.linspace(1, 10, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "80000\n",
      "90000\n",
      "Initialization time for list of Langmuir objects:\n",
      "4860.82978487\n"
     ]
    }
   ],
   "source": [
    "# There's a better way to do this with iterators\n",
    "data = []\n",
    "\n",
    "start_time = time.time()\n",
    "for itr in itertools.product(emitter_temps, emitter_barriers, collector_barriers, collector_voltages, collector_positions):\n",
    "    # Construct dictionaries out of the combination of parameters\n",
    "    em_dict = dict([itm[1:] for itm in itr if itm[0] == \"emitter\"])\n",
    "    co_dict = dict([itm[1:] for itm in itr if itm[0] == \"collector\"])\n",
    "    \n",
    "    # Update the dictionaries used to initialize the TEC electrodes\n",
    "    em_params = dict(em_params.items() + em_dict.items())\n",
    "    co_params = dict(co_params.items() + co_dict.items())\n",
    "    \n",
    "    # Create electrodes and `Langmuir` objects\n",
    "    em = tec.electrode.Metal.from_dict(em_params)\n",
    "    co = tec.electrode.Metal.from_dict(co_params)\n",
    "    \n",
    "    data.append(tec.models.Langmuir(em, co))\n",
    "    \n",
    "print \"Initialization time for list of Langmuir objects:\"\n",
    "print time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write time of JSON formatted file:\n",
      "4984.23444796\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "with open(\"data.json\", \"w\") as f:\n",
    "    f.write(json.dumps(data, default=tec.io.to_json, indent=4))\n",
    "\n",
    "print \"Write time of JSON formatted file:\"\n",
    "print time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of data array:\n",
      "100000\n",
      "Size of data array in memory\n",
      "824472\n"
     ]
    }
   ],
   "source": [
    "print \"Length of data array:\"\n",
    "print len(data)\n",
    "print \"Size of data array in memory\"\n",
    "print sys.getsizeof(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and train Neural Network\n",
    "The following code converts the data calculated above to a form that can be used by [Nielsen's neural network code](https://github.com/mnielsen/neural-networks-and-deep-learning). Additionally, the network is set up and trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"data.json\", \"r\") as f:\n",
    "    complete_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_dat(datum):\n",
    "    \"\"\"\n",
    "    Convert dict data output by tec to tuple for neural net\n",
    "    \n",
    "    This function converts dictionary data output by the `tec` module\n",
    "    to the 2-tuple format required by the NNADL [1] code.\n",
    "    The zeroth element of the 2-tuple is a numpy array containing the\n",
    "    independent variables, and the first element is the dependent variable.\n",
    "    This function orders the independent variables from the dict to the \n",
    "    numpy array as follows:\n",
    "    \n",
    "    * collector barrier\n",
    "    * collector temp\n",
    "    * collector voltage\n",
    "    * collector position\n",
    "    * collector richardson\n",
    "    * collector emissivity\n",
    "    * emitter barrier\n",
    "    * emitter temp\n",
    "    * emitter voltage\n",
    "    * emitter position\n",
    "    * emitter richardson\n",
    "    * emitter emissivity\n",
    "    \n",
    "    [1] https://github.com/mnielsen/neural-networks-and-deep-learning\n",
    "    \"\"\"\n",
    "    electrodes = (\"collector\", \"emitter\")\n",
    "    attributes = (\"barrier\", \"temp\", \"voltage\", \"position\", \"richardson\", \"emissivity\")\n",
    "    \n",
    "    abscissae = np.array([datum[electrode][attribute] for electrode, attribute in itertools.product(electrodes, attributes)])\n",
    "    abscissae_matrix = np.ndarray(buffer=abscissae, shape=(12, 1))\n",
    "    ordinate = datum[\"max_motive\"]\n",
    "    \n",
    "    return (abscissae_matrix, ordinate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = [convert_dat(datum) for datum in complete_data[0:50000]]\n",
    "test_data = [convert_dat(datum) for datum in complete_data[50001:80000]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "net = network.Network([12, 30, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 complete\n",
      "Epoch 1 complete\n",
      "Epoch 2 complete\n",
      "Epoch 3 complete\n",
      "Epoch 4 complete\n",
      "Epoch 5 complete\n",
      "Epoch 6 complete\n",
      "Epoch 7 complete\n",
      "Epoch 8 complete\n",
      "Epoch 9 complete\n"
     ]
    }
   ],
   "source": [
    "net.SGD(training_data, 10, 10, 3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
